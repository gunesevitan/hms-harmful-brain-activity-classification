{
  "fold1": {
    "training_history": {
      "training_kl_divergence": [
        0.7585294246673584,
        0.5244162082672119,
        0.4291324317455292,
        0.36526456475257874,
        0.36635738611221313
      ],
      "validation_kl_divergence": [
        0.6130552291870117,
        0.5489868521690369,
        0.49886980652809143,
        0.49725350737571716,
        0.5386849641799927
      ]
    },
    "best_epoch_kl_divergence": 4,
    "training_kl_divergence": 0.36526456475257874,
    "validation_kl_divergence": 0.49725350737571716
  },
  "fold2": {
    "training_history": {
      "training_kl_divergence": [
        0.7807342410087585,
        0.5355331301689148,
        0.4330272972583771,
        0.3661653697490692,
        0.3677714765071869
      ],
      "validation_kl_divergence": [
        0.6101600527763367,
        0.5294093489646912,
        0.5089932084083557,
        0.5065671801567078,
        0.5353184938430786
      ]
    },
    "best_epoch_kl_divergence": 4,
    "training_kl_divergence": 0.3661653697490692,
    "validation_kl_divergence": 0.5065671801567078
  },
  "fold3": {
    "training_history": {
      "training_kl_divergence": [
        0.7620818018913269,
        0.5216495394706726,
        0.4252376854419708,
        0.3633964955806732,
        0.3589117228984833
      ],
      "validation_kl_divergence": [
        0.6137862801551819,
        0.5978602170944214,
        0.5314277410507202,
        0.5187608003616333,
        0.5308101773262024
      ]
    },
    "best_epoch_kl_divergence": 4,
    "training_kl_divergence": 0.3633964955806732,
    "validation_kl_divergence": 0.5187608003616333
  },
  "fold4": {
    "training_history": {
      "training_kl_divergence": [
        0.7480638027191162,
        0.5205914378166199,
        0.41887038946151733,
        0.35636332631111145,
        0.36518609523773193
      ],
      "validation_kl_divergence": [
        0.7536391019821167,
        0.581139862537384,
        0.548656165599823,
        0.5391052961349487,
        0.6407716870307922
      ]
    },
    "best_epoch_kl_divergence": 4,
    "training_kl_divergence": 0.35636332631111145,
    "validation_kl_divergence": 0.5391052961349487
  },
  "fold5": {
    "training_history": {
      "training_kl_divergence": [
        0.7756057381629944,
        0.5290384292602539,
        0.4320911467075348,
        0.36500808596611023,
        0.36377811431884766
      ],
      "validation_kl_divergence": [
        0.6831142902374268,
        0.5942521095275879,
        0.5401558876037598,
        0.5461143851280212,
        0.5601795315742493
      ]
    },
    "best_epoch_kl_divergence": 3,
    "training_kl_divergence": 0.4320911467075348,
    "validation_kl_divergence": 0.5401558876037598
  }
}