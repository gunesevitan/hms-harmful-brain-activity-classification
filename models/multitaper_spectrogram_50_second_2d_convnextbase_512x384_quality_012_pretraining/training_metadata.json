{
  "fold1": {
    "training_history": {
      "training_kl_divergence": [
        0.7474714517593384,
        0.5189021229743958,
        0.44189223647117615,
        0.3869461119174957,
        0.3665284216403961
      ],
      "validation_kl_divergence": [
        0.5714331269264221,
        0.5263552665710449,
        0.5165705680847168,
        0.5280622839927673,
        0.5252625942230225
      ]
    },
    "best_epoch_kl_divergence": 3,
    "training_kl_divergence": 0.44189223647117615,
    "validation_kl_divergence": 0.5165705680847168
  },
  "fold2": {
    "training_history": {
      "training_kl_divergence": [
        0.7361042499542236,
        0.5171088576316833,
        0.438744455575943,
        0.38136306405067444,
        0.3611108958721161
      ],
      "validation_kl_divergence": [
        0.624119758605957,
        0.5417546629905701,
        0.5288674831390381,
        0.5461179614067078,
        0.6020460724830627
      ]
    },
    "best_epoch_kl_divergence": 3,
    "training_kl_divergence": 0.438744455575943,
    "validation_kl_divergence": 0.5288674831390381
  },
  "fold3": {
    "training_history": {
      "training_kl_divergence": [
        0.7380140423774719,
        0.5130207538604736,
        0.4332725703716278,
        0.38273394107818604,
        0.35684841871261597
      ],
      "validation_kl_divergence": [
        0.6086276173591614,
        0.6184002757072449,
        0.5627365112304688,
        0.5639436841011047,
        0.5785359740257263
      ]
    },
    "best_epoch_kl_divergence": 3,
    "training_kl_divergence": 0.4332725703716278,
    "validation_kl_divergence": 0.5627365112304688
  },
  "fold4": {
    "training_history": {
      "training_kl_divergence": [
        0.7255458831787109,
        0.49712252616882324,
        0.4215743839740753,
        0.36878731846809387,
        0.3525605797767639
      ],
      "validation_kl_divergence": [
        0.7289592027664185,
        0.6224499940872192,
        0.5920260548591614,
        0.6049062013626099,
        0.6765413880348206
      ]
    },
    "best_epoch_kl_divergence": 3,
    "training_kl_divergence": 0.4215743839740753,
    "validation_kl_divergence": 0.5920260548591614
  },
  "fold5": {
    "training_history": {
      "training_kl_divergence": [
        0.7330957651138306,
        0.5148606896400452,
        0.4364771544933319,
        0.3824194371700287,
        0.36077767610549927
      ],
      "validation_kl_divergence": [
        0.6916686296463013,
        0.6324872374534607,
        0.5882501006126404,
        0.5775718688964844,
        0.6105829477310181
      ]
    },
    "best_epoch_kl_divergence": 4,
    "training_kl_divergence": 0.3824194371700287,
    "validation_kl_divergence": 0.5775718688964844
  }
}